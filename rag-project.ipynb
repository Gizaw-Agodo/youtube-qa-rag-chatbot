{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48c3931-e2c0-43be-be54-da1438bfbeb3",
   "metadata": {},
   "source": [
    "# LangChain Pipeline: YouTube Transcript + Parallel Chains\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "- Fetch a transcript from a YouTube video using `youtube-transcript-api`\n",
    "- Split it into chunks\n",
    "- Create embeddings with OpenAI\n",
    "- Store vectors in FAISS\n",
    "- Use LangChain's `RunnableParallel` to run retrieval and summarization in parallel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d11f1d-97f0-4f7a-9d5e-c182cda59a62",
   "metadata": {},
   "source": [
    "### Setup and Imports\n",
    "\n",
    "This section imports all necessary libraries and modules required for fetching transcripts, processing text, embedding, vector storage, prompt creation, and running the language model chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "396b027e-8e5b-415d-a492-43405229bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7648e2c-2140-41ad-89e4-7117c4c7f75b",
   "metadata": {},
   "source": [
    "### Load Environment Variables\n",
    "\n",
    "Load the OpenAI API key from the `.env` file to authenticate API requests securely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59ca30bd-4f7d-47ec-bfab-0a3028679ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"env\")\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e61f323-49a6-4238-b7cf-661cc17e376c",
   "metadata": {},
   "source": [
    "### Fetch YouTube Video Transcript\n",
    "\n",
    "Function to fetch the transcript of a YouTube video by its ID. Handles the case where transcripts might be disabled gracefully.\n",
    "python\n",
    "Copy\n",
    "Edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "408041bc-5b38-4129-8dc7-9b28fed71b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVideoTranscript(video_id): \n",
    "    try:\n",
    "        api = YouTubeTranscriptApi()\n",
    "        transcript_list = api.fetch(video_id=video_id)\n",
    "        transcript = \" \".join(chunk.text for chunk in transcript_list.snippets)\n",
    "        return transcript\n",
    "    except TranscriptsDisabled:\n",
    "        return None\n",
    "\n",
    "transcript = getVideoTranscript(video_id = \"Gfr50f6ZBvo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d028c-5b15-474f-93fd-359ecc7ae947",
   "metadata": {},
   "source": [
    "### Split Transcript into Chunks\n",
    "\n",
    "Split the entire transcript text into smaller chunks to make embedding and retrieval more efficient. We use an overlap to maintain context between chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6ffd363-9166-460d-91a9-84e75f12bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.create_documents([transcript])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b3a3fb-45c0-4f83-ba0c-07704f135032",
   "metadata": {},
   "source": [
    "### Create Embeddings and Vector Store\n",
    "\n",
    "Generate vector embeddings from the chunks using OpenAI embeddings, then store them in a FAISS vector store for similarity search.\n",
    "python\n",
    "Copy\n",
    "Edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e490e1e-5d15-4ce4-a0ea-c065865e1dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74833690-0d0a-4b7c-94b7-40decaf9afe7",
   "metadata": {},
   "source": [
    "### Define Prompt Template\n",
    "\n",
    "Set up a prompt template that guides the language model to answer questions using only the retrieved transcript context. If there is insufficient context, the model responds accordingly.\n",
    "python\n",
    "Copy\n",
    "Edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fe8758f-4246-4ac0-943d-7ef6573480f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "      You are a helpful assistant.\n",
    "      Answer ONLY from the provided transcript context.\n",
    "      If the context is insufficient, just say you don't know.\n",
    "\n",
    "      {context}\n",
    "      Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables = ['context', 'question']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e449348-8c01-416a-95e9-53943498b988",
   "metadata": {},
   "source": [
    "### Setup Retriever and Formatter\n",
    "\n",
    "Configure a retriever to find the top 4 most similar transcript chunks for a given question and a formatter to concatenate retrieved document texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3862780-8c62-411c-8e81-543b9d20d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
    "\n",
    "def formatter(retrieved_docs) : \n",
    "    return  \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17da1fd0-dc45-4907-9f3a-c2094ad43578",
   "metadata": {},
   "source": [
    "### Build Parallel Chain\n",
    "\n",
    "Create a parallel runnable that runs retrieval and formatting of context alongside passing the question forward in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709115a0-7cbc-4720-b6e0-5669d7bb5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "    'context': retriever | RunnableLambda(formatter),\n",
    "    'question': RunnablePassthrough()\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19769087-5275-47c8-bb17-3429b258d6ef",
   "metadata": {},
   "source": [
    "### Initialize Language Model and Parser\n",
    "\n",
    "Set up the ChatOpenAI language model (GPT-4o-mini) with a low temperature for deterministic responses, and an output parser to extract the final string response.\n",
    "python\n",
    "Copy\n",
    "Edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b14c6d9-e37c-4bce-b861-ce593961a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df6f86c-4039-43b5-aa79-341f8f7a8462",
   "metadata": {},
   "source": [
    "### Combine Chain Components\n",
    "\n",
    "Chain together retrieval, prompt formatting, language model inference, and parsing into one end-to-end processing pipeline.\n",
    "python\n",
    "Copy\n",
    "Edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef421a2c-4ba0-4a4d-a203-564b1c2edabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = parallel_chain | prompt | llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f46eb8-196c-4f2b-aa1d-53565c3f85d9",
   "metadata": {},
   "source": [
    "### Ask a Question\n",
    "\n",
    "Invoke the chain with a sample question regarding the video transcript and print the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cea57ed2-d983-48ed-bf6f-86ca9ec34291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, the topic of aliens is discussed in this video. The speaker expresses their personal opinion that they believe we are likely alone in the universe, citing a lack of evidence for the existence of alien civilizations. They mention that despite the advancements in technology and searches for extraterrestrial life, we have not heard any signs of alien civilizations. The speaker also discusses the possibility of different types of alien civilizations, their potential behaviors, and the idea of a \"great filter\" that might prevent civilizations from advancing to a multi-planetary stage. They reflect on the implications of these questions for humanity, particularly regarding self-destruction.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question  = \"is the topic of aliens discussed in this video? if yes then what was discussed\"\n",
    "answer = chain.invoke(question)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e347e-f694-4cb5-913a-708a09c98ab6",
   "metadata": {},
   "source": [
    "### Visualize Chain Graph (Optional)\n",
    "\n",
    "Print an ASCII diagram showing the flow and components of the chain pipeline for debugging or learning purposes.\n",
    "python\n",
    "Copy\n",
    "Edit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0375f2a-4886-4243-a3ae-bbb78ea0994a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            +---------------------------------+         \n",
      "            | Parallel<context,question>Input |         \n",
      "            +---------------------------------+         \n",
      "                    **               ***                \n",
      "                 ***                    **              \n",
      "               **                         ***           \n",
      "+----------------------+                     **         \n",
      "| VectorStoreRetriever |                      *         \n",
      "+----------------------+                      *         \n",
      "            *                                 *         \n",
      "            *                                 *         \n",
      "            *                                 *         \n",
      "      +-----------+                    +-------------+  \n",
      "      | formatter |                    | Passthrough |  \n",
      "      +-----------+*                   +-------------+  \n",
      "                    **               ***                \n",
      "                      ***         ***                   \n",
      "                         **     **                      \n",
      "           +----------------------------------+         \n",
      "           | Parallel<context,question>Output |         \n",
      "           +----------------------------------+         \n",
      "                             *                          \n",
      "                             *                          \n",
      "                             *                          \n",
      "                    +----------------+                  \n",
      "                    | PromptTemplate |                  \n",
      "                    +----------------+                  \n",
      "                             *                          \n",
      "                             *                          \n",
      "                             *                          \n",
      "                      +------------+                    \n",
      "                      | ChatOpenAI |                    \n",
      "                      +------------+                    \n",
      "                             *                          \n",
      "                             *                          \n",
      "                             *                          \n",
      "                    +-----------------+                 \n",
      "                    | StrOutputParser |                 \n",
      "                    +-----------------+                 \n",
      "                             *                          \n",
      "                             *                          \n",
      "                             *                          \n",
      "                 +-----------------------+              \n",
      "                 | StrOutputParserOutput |              \n",
      "                 +-----------------------+              \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48b10f-252f-4ba3-a29c-d3d4952e9ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:langchain_env]",
   "language": "python",
   "name": "conda-env-langchain_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
